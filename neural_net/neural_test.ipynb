{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_network:\n",
    "    def __init__(self,input_neurons,hidden_neurons,output_neurons,learning_rate):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの初期化\n",
    "        \"\"\"\n",
    "        self.inneurons=input_neurons #入力層のニューロン数\n",
    "        self.hneurons=hidden_neurons #隠れ層のニューロン数\n",
    "        self.oneurons=output_neurons #出力層のニューロン数\n",
    "        self.lr=learning_rate #学習率\n",
    "        self.weight_initializer()\n",
    "    \n",
    "    def weight_initializer(self):\n",
    "        self.w1=np.random.normal(\n",
    "        0.0,\n",
    "        pow(self.hneurons,-0.5),\n",
    "        (self.oneurons,\n",
    "        self.hneurons+1)\n",
    "        )\n",
    "        self.w2=np.random.normal(\n",
    "                 0.0,\n",
    "                 pow(self.hneurons,-0.5),\n",
    "                 (self.oneurons,\n",
    "                 self.hneurons+1)\n",
    "                 )\n",
    "        self.w_o=np.random.normal(\n",
    "                0.0,\n",
    "                pow(self.hneurons,-0.5),\n",
    "                (self.oneurons,\n",
    "                self.hneurons+1)\n",
    "                )\n",
    "        \n",
    "    def sigmoid(self,x):#シグモイド\n",
    "        return 1/(1+exp(-x))\n",
    "    \n",
    "    def softmax(self,x):\n",
    "        c=np.max(x)\n",
    "        exp_x=np.exp(x-c)\n",
    "        sum_exp=np.sum(exp_x)\n",
    "        y=exp_x/sum_exp_x\n",
    "        return y\n",
    "    \n",
    "    def train(self,inputs_list,targets_list):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの学習を行う\n",
    "        ----\n",
    "        inputs_list:訓練データの配列\n",
    "        targets_list:正解ラベル\n",
    "        \"\"\"\n",
    "        inputs=np.array(\n",
    "                np.append(\n",
    "                inputs_list,[1]),\n",
    "                ndmin=2 #二次元化\n",
    "                ).T\n",
    "        ##隠れ層\n",
    "        hidden_outputs=np.dot(\n",
    "        self.w1, #隠れ層の重み\n",
    "        inputs # 入力層の出力\n",
    "        )\n",
    "        \n",
    "        hidden_outputs=self.sigmoid(hidden_inputs)\n",
    "        hidden_outputs=np.append(\n",
    "                        hidden_outputs\n",
    "                        [[1]],\n",
    "                        axis=0)\n",
    "        #ここからP208[出力層]）\n",
    "        \n",
    "        ## 出力層\n",
    "        \n",
    "        final_inputs=np.dot(\n",
    "                     self.w2,\n",
    "                     hidden_outs)\n",
    "        \n",
    "        # 活性化関数を適用して出力層から出力する\n",
    "        final_outputs=self.softmax(final_inputs)\n",
    "        \n",
    "        ## バックプロパゲーション\n",
    "        # 正解ラベルの配列を1列の行列に変換する\n",
    "        targets=np.array(\n",
    "        targets_list,\n",
    "        ndmin=2).T\n",
    "        \n",
    "        #出力地と正解ラベルとの誤差\n",
    "        out_errors=final_outputs -targets\n",
    "        #出力値と正解ラベルとの誤差\n",
    "        delta_output = output_errors*(1 - final_outputs)*final_outputs\n",
    "        \n",
    "        #重みを更新する前に隠れ層の出力誤差を求めておく\n",
    "        hidden_errors=np.dot(\n",
    "        self.w2.T,\n",
    "        delta_output)\n",
    "        \n",
    "        # 出力層の重み、バイアスの更新\n",
    "        self.w2-=self.lr*np.dot(\n",
    "        #出力の誤差*(1-出力信号)*出力信号\n",
    "        delta_output,\n",
    "        # 隠れ層の出力行列の転置\n",
    "        hidden_outputs.T)\n",
    "        \n",
    "        print(final_outputs)\n",
    "        print(sum(final_outputs))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (10,11) and (4,1) not aligned: 11 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-293cd42f9b41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0minputs_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtargets_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-9340422d7049>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[0;32m     56\u001b[0m         hidden_outputs=np.dot(\n\u001b[0;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#隠れ層の重み\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;31m# 入力層の出力\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         )\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (10,11) and (4,1) not aligned: 11 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "input_neurons=10\n",
    "hidden_neurons=10\n",
    "output_neurons=10\n",
    "learning_rate=0.1\n",
    "\n",
    "n=Neural_network(input_neurons,\n",
    "                hidden_neurons,\n",
    "                output_neurons,\n",
    "                learning_rate)\n",
    "\n",
    "inputs_list=[1.0,1.5,2.0]\n",
    "targets_list=[1.0,1.5,2.0]\n",
    "n.train(inputs_list,targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
