{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_network:\n",
    "    def __init__(self,input_neurons,hidden_neurons,output_neurons,learning_rate):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの初期化\n",
    "        \"\"\"\n",
    "        self.inneurons=input_neurons #入力層のニューロン数\n",
    "        self.hneurons=hidden_neurons #隠れ層のニューロン数\n",
    "        self.oneurons=output_neurons #出力層のニューロン数\n",
    "        self.lr=learning_rate #学習率\n",
    "        self.weight_initializer()\n",
    "    \n",
    "    def weight_initializer(self):\n",
    "        self.w1=np.random.normal(\n",
    "        0.0,\n",
    "        pow(self.inneurons,-0.5),\n",
    "        (self.hneurons,\n",
    "        self.inneurons+1)\n",
    "        )\n",
    "        self.w2=np.random.normal(\n",
    "                 0.0,\n",
    "                 pow(self.hneurons,-0.5),\n",
    "                 (self.oneurons,\n",
    "                 self.hneurons+1)\n",
    "                 )\n",
    "        \"\"\"\n",
    "        self.w_o=np.random.normal(\n",
    "                0.0,\n",
    "                pow(self.hneurons,-0.5),\n",
    "                (self.oneurons,\n",
    "                self.hneurons+1)\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "    def sigmoid(self,x):#シグモイド\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def softmax(self,x):\n",
    "        c=np.max(x)\n",
    "        exp_x=np.exp(x-c)\n",
    "        sum_exp_x=np.sum(exp_x)\n",
    "        y=exp_x/sum_exp_x\n",
    "        return y\n",
    "    \n",
    "    def train(self,inputs_list,targets_list):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの学習を行う\n",
    "        ----\n",
    "        inputs_list:訓練データの配列\n",
    "        targets_list:正解ラベル\n",
    "        \"\"\"\n",
    "        inputs=np.array(\n",
    "                np.append(\n",
    "                inputs_list,[1]),\n",
    "                ndmin=2 #二次元化\n",
    "                ).T\n",
    "        ##隠れ層\n",
    "        \n",
    "        #入力層の出力に重み、バイアスをてきようして隠れ層に入力する\n",
    "        hidden_inputs=np.dot(self.w1,inputs)\n",
    "        \n",
    "        #活性化関数を適用せて隠れ層からの出力\n",
    "        hidden_outputs=self.sigmoid(hidden_inputs)\n",
    "        #隠れ層の出力行列の末尾にバイアスのための[1]を追加\n",
    "        hidden_outputs=np.append(\n",
    "                        hidden_outputs,\n",
    "                        [[1]],\n",
    "                        axis=0)\n",
    "        \n",
    "        ## [出力層]\n",
    "        #出力層への入力信号の計算\n",
    "        final_inputs=np.dot(\n",
    "                     self.w2,\n",
    "                     hidden_outputs)\n",
    "        \n",
    "        # 活性化関数を適用して出力層から出力する\n",
    "        final_outputs=self.softmax(final_inputs)\n",
    "        \n",
    "        ## バックプロパゲーション\n",
    "        # 正解ラベルの配列を1列の行列に変換する\n",
    "        targets=np.array(\n",
    "        targets_list,\n",
    "        ndmin=2).T\n",
    "        \n",
    "        #出力地と正解ラベルとの誤差\n",
    "        output_errors=final_outputs -targets\n",
    "        #出力値と正解ラベルとの誤差\n",
    "        delta_output = output_errors*(1 - final_outputs)*final_outputs\n",
    "        \n",
    "        #重みを更新する前に隠れ層の出力誤差を求めておく\n",
    "        hidden_errors=np.dot(\n",
    "        self.w2.T,\n",
    "        delta_output)\n",
    "        \n",
    "        # 出力層の重み、バイアスの更新\n",
    "        self.w2-=self.lr*np.dot(\n",
    "        #出力の誤差*(1-出力信号)*出力信号\n",
    "        delta_output,\n",
    "        # 隠れ層の出力行列の転置\n",
    "        hidden_outputs.T)\n",
    "        \n",
    "        print(final_outputs)\n",
    "        print(sum(final_outputs))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08351605]\n",
      " [0.17555446]\n",
      " [0.74092949]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "input_neurons=3\n",
    "hidden_neurons=3\n",
    "output_neurons=3\n",
    "learning_rate=0.1\n",
    "\n",
    "n=Neural_network(input_neurons,\n",
    "                hidden_neurons,\n",
    "                output_neurons,\n",
    "                learning_rate)\n",
    "\n",
    "inputs_list=[1.0,1.5,2.0]\n",
    "targets_list=[1.0,1.5,2.0]\n",
    "n.train(inputs_list,targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
