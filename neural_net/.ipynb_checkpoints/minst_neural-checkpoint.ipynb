{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_network:\n",
    "    def __init__(self,input_neurons,hidden_neurons,output_neurons,learning_rate):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの初期化\n",
    "        \"\"\"\n",
    "        self.inneurons=input_neurons #入力層のニューロン数\n",
    "        self.hneurons=hidden_neurons #隠れ層のニューロン数\n",
    "        self.oneurons=output_neurons #出力層のニューロン数\n",
    "        self.lr=learning_rate #学習率\n",
    "        self.weight_initializer()\n",
    "    \n",
    "    def weight_initializer(self):\n",
    "        self.w1=np.random.normal(\n",
    "        0.0,\n",
    "        pow(self.inneurons,-0.5),\n",
    "        (self.hneurons,\n",
    "        self.inneurons+1)\n",
    "        )\n",
    "        self.w2=np.random.normal(\n",
    "                 0.0,\n",
    "                 pow(self.hneurons,-0.5),\n",
    "                 (self.oneurons,\n",
    "                 self.hneurons+1)\n",
    "                 )\n",
    "        \"\"\"\n",
    "        self.w_o=np.random.normal(\n",
    "                0.0,\n",
    "                pow(self.hneurons,-0.5),\n",
    "                (self.oneurons,\n",
    "                self.hneurons+1)\n",
    "                )\n",
    "        \"\"\"\n",
    "        \n",
    "    def sigmoid(self,x):#シグモイド\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def softmax(self,x):\n",
    "        c=np.max(x)\n",
    "        exp_x=np.exp(x-c)#オーバーフロー防止\n",
    "        sum_exp_x=np.sum(exp_x)\n",
    "        y=exp_x/sum_exp_x\n",
    "        return y\n",
    "    \n",
    "    def train(self,inputs_list,targets_list):\n",
    "        \"\"\"\n",
    "        ニューラルネットワークの学習を行う\n",
    "        ----\n",
    "        inputs_list:訓練データの配列\n",
    "        targets_list:正解ラベル\n",
    "        \"\"\"\n",
    "        ##　入力層\n",
    "        inputs=np.array(\n",
    "                np.append(\n",
    "                inputs_list,[1]),\n",
    "                ndmin=2 #二次元化\n",
    "                ).T\n",
    "        ##隠れ層\n",
    "        \n",
    "        #入力層の出力に重み、バイアスをてきようして隠れ層に入力する\n",
    "        hidden_inputs=np.dot(self.w1,inputs)\n",
    "        \n",
    "        #活性化関数を適用せて隠れ層からの出力\n",
    "        hidden_outputs=self.sigmoid(hidden_inputs)\n",
    "        #隠れ層の出力行列の末尾にバイアスのための[1]を追加\n",
    "        hidden_outputs=np.append(\n",
    "                        hidden_outputs,\n",
    "                        [[1]],\n",
    "                        axis=0)\n",
    "        \n",
    "        ## [出力層]\n",
    "        #出力層への入力信号の計算\n",
    "        final_inputs=np.dot(\n",
    "                     self.w2,\n",
    "                     hidden_outputs)\n",
    "        \n",
    "        # 活性化関数を適用して出力層から出力する\n",
    "        final_outputs=self.softmax(final_inputs)\n",
    "        \n",
    "        ## バックプロパゲーション\n",
    "        # 正解ラベルの配列を1列の行列に変換する\n",
    "        targets=np.array(\n",
    "        targets_list,\n",
    "        ndmin=2).T\n",
    "        \n",
    "        #出力地と正解ラベルとの誤差\n",
    "        output_errors=final_outputs -targets\n",
    "        #出力値と正解ラベルとの誤差\n",
    "        delta_output = output_errors*(1 - final_outputs)*final_outputs\n",
    "        \n",
    "        #重みを更新する前に隠れ層の出力誤差を求めておく\n",
    "        hidden_errors=np.dot(\n",
    "        self.w2.T,\n",
    "        delta_output)\n",
    "        \n",
    "        # 出力層の重み、バイアスの更新\n",
    "        self.w2-=self.lr*np.dot(\n",
    "        #出力の誤差*(1-出力信号)*出力信号\n",
    "        delta_output,\n",
    "        # 隠れ層の出力行列の転置\n",
    "        hidden_outputs.T)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##　バックプロパゲーション(隠れ層)\n",
    "        \n",
    "        #逆伝播された出力誤差からバイアスのものを取り除く\n",
    "        hidden_errors_nobias=np.delete(\n",
    "        hidden_errors,\n",
    "        self.hneurons,\n",
    "        axis=0\n",
    "        )\n",
    "        \n",
    "        #隠れ層の出力行列からバイアスを除く\n",
    "        hidden_outputs_nobias=np.delete(\n",
    "        hidden_outputs,\n",
    "        self.hneurons,\n",
    "        axis=0)\n",
    "        \n",
    "        #隠れ層の重み,バイアスの更新\n",
    "        self.w1-=self.lr*np.dot(\n",
    "        hidden_errors_nobias*(1.0-hidden_outputs_nobias\n",
    "                             )*hidden_outputs_nobias,\n",
    "        #入力層の出力信号の行列を転置\n",
    "        inputs.T\n",
    "        )\n",
    "    \n",
    "    def evaluate(self,inputs_list):\n",
    "        \"\"\"\n",
    "        学習した重みでテストデータを評価する\n",
    "        \"\"\"\n",
    "        ##入力層\n",
    "        inputs=np.array(\n",
    "        np.append(inputs_list,[1]),\n",
    "        ndmin=2).T\n",
    "        \n",
    "        ##隠れ層\n",
    "        #入力層の出力に重み、バイアスをてきようして隠れ層に入力する\n",
    "        hidden_inputs=np.dot(self.w1,inputs)\n",
    "        #活性化関数を適用して隠れ層から出力する\n",
    "        hidden_outputs=self.sigmoid(hidden_inputs)\n",
    "        \n",
    "        \n",
    "        ##出力層\n",
    "        final_inputs=np.dot(self.w2,\n",
    "                           np.append(hidden_outputs,[1]),)\n",
    "        \n",
    "        #活性化関数を適用して出力層から出力する\n",
    "        final_outputs=self.softmax(final_inputs)\n",
    "        \n",
    "        #出力層から出力を戻り値として返す\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 78s 7us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_trains,y_trains),(x_tests,y_tests)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
